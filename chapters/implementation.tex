\chapter{Implementation\label{ch:implementation}}

\epigraph{Talk is cheap. Show me the code.}{\textit{Linus Torvalds}}

In this chapter we look at the Rust implementation of CMR\@. The source code is openly available
on GitHub under the MIT license~\cite{cmr-github}.

This chapter is organized as follows: \cref{sec:impl-data} discusses briefly the most important
data that CMR defines, both global and thread local;
\cref{sec:impl-primitives} shows the implementation of the primitives from
\cref{sec:cmr-primitives}, and argues for their correctness by the definitions in the previous
chapter;
\cref{sec:impl-snapshot} explains how memory snapshotting, an important part of CMR, is
implemented;
\cref{sec:impl-reachability} describes the reachability analysis including important details of the
Rust type system;
\cref{sec:impl-communication} mentions how communication between the parent and child process;
we finish the chapter with \cref{sec:impl-complications} where we highlight a few of the
complications that we encountered during the implementation of CMR.

\clearpage

\section{Data\label{sec:impl-data}}

In order to better understand how CMR is laid out, we start out by looking at the data.
As Fred Brooks~\cite{brooks1995mythical} said:
\begin{displayquote}
Show me your flowcharts and conceal your tables, and I shall continue to be mystified. Show me your
  tables, and I won't usually need your flowcharts; they'll be obvious.
\end{displayquote}

Allocated addresses are stored in a global \code{HashSet}, \code{ALLOCS}, which uses a \code{Mutex}
for thread synchronization. Only addresses in \code{ALLOCS} are subject for reclamation.
\cref{sec:impl-trace} explains more about the way allocations are stored in order to preserve type
information.

Thread also stores data in \gls{tls}. Each thread maintains a \code{Vec} of pointers to their
\code{Guard}s, such that collecting all guards is just a matter of iterating through the
\code{Vec}, and following the pointer. Since the data is thread local, no synchronization is needed
when operating on the \code{Vec}, which makes updates cheap.
In addition all threads store the allocations they have done since the last reclamation pass;
these allocations are ``stolen'' by the reclaiming thread in each pass. See
\cref{sec:impl-signalvec} for the details.

One caveat of CMR is that new threads needs to register themselves before using the system. This is
done through \code{cmr::register_thread()}. This initializes thread local data, and pushes a thread
handle used in \cref{sec:impl-snapshot}. We summarize some of the problems in
\cref{sec:impl-thread-registration}, and note that this is still a pain point of the
implementation.

Only one thread may be in a reclamation pass at any given time, and we limit this by having a
global \code{reclaim_lock}. A thread wanting to reclaim grabs the lock before doing anything else
in the reclamation procedure; this lock is later freed (see
\cref{sec:impl-communication}). If a thread attempts to do a reclamation pass but finds that the
lock is taken, it simply does not do the pass; waiting for the lock to be released would only
increase the latency of the reclamation pass for that thread, and since a reclamation pass was
recently performed, chances are that there will be very few new allocations to free in the pass.



\section{Primitives\label{sec:impl-primitives}}

In this section we present implementation of the primitives as presented in
\cref{sec:cmr-primitives}, and show that the implementation is unifiable with the definitions of
\cref{ch:cmr}. All \code{struct}s are shown with their full definitions, but we show only
highlights of the methods of the \code{struct}s, as most of them are trivial.

\subsubsection{Guard}

The \code{Guard} is implemented as a single word, in addition to an empty type (the
\code{PhantomData}) as Rust requires generic types to be used. \code{Guard}s aren't normally
constructed directly, but rather declared with the \code{guard!} macro, which constructs it and
calls \code{Guard::register}.  An excerpt of the definitions of \code{Guard} is shown in
\cref{lst:guard-impl}.

\begin{figure}
\input{listings/guard}
\end{figure}

\code{Guard::register} gets a mutable reference to the thread local \code{Vec} of \code{Guard}s,
and inserts a pointer to itself into it. \code{Guard::drop} (omitted) does the opposite.
\code{Guard::new} is marked \code{unsafe} since the caller must guarantee to \code{register} the
guard before using it. This is normally handled by the \code{guard!} macro, but there are use cases
for calling \code{new} directly. Usage of the guard is normally as follows:
\begin{lstlisting}[style=Rust]
{
  guard!(g);
  let my_num = cmr::alloc(123, g);
  println!("{}", my_num); // prints `123`
} // `g` is dropped here, and `my_num` is ripe for deallocation
\end{lstlisting}
Note that by using \code{guard!}, the caller only obtains a \code{\&mut Guard<T>}, and not the
\code{Guard<T>} itself; this makes it impossible to move the \code{Guard} in memory.


\subsubsection{Atomic}

\code{Atomic} is mainly a wrapper around Rusts \code{AtomicPtr}, although the internals differ
slightly. CMR defines its own type so that we can control the return types of certain functions.
\cref{lst:def-atomic} shows the definition of the \code{struct}, as well as \code{cas}, the
compare-and-swap operation, in which we utilize some Traits from the Rust standard library to
convert between types.  Implementation of remaining methods are straight forward.

\input{listings/atomic}

\pagebreak
\subsubsection{NullablePtr}

\code{NullablePtr} is used as the canonical pointer type in CMR, and all pointer like types are
converted to \code{NullablePtr} using the \code{From} and \code{Into} traits from the Rust standard
library, which handles conversion between types. For instance, we implement \code{From<*const T> for
NullablePtr<T>}. This way we can write functions that are generic over all types of pointers, so
that the user of CMR does not have to handle these conversions themselves.


The definition of \code{NullablePtr} is shown in \cref{lst:def-nullableptr}, with the \code{new}
and \code{ptr} methods. Note that we cannot get a reference to the \code{T} that \code{NullablePtr}
points to; this is because we don't know if the pointer is \code{null} or not. \code{ptr} promotes
the \code{NullablePtr} to a \code{Ptr}, should it not be \code{null}, by using the \code{Option}
type which Rust provides.

\begin{figure}[ht]
  \begin{lstlisting}[style=Rust,label=lst:def-nullableptr,
  caption=Definition of \code{NullablePtr}]
pub struct NullablePtr<'a, T: 'a>(usize, PhantomData<&'a T>);
impl<'a, T> NullablePtr<'a, T> {
    pub fn new(u: usize) -> Self { NullablePtr(u, PhantomData) }
    pub fn ptr(self) -> Option<Ptr<'a, T>> {
        if addr(self) == 0 { None }
        else { unsafe { Some(Ptr::new(raw(self))) } }
    (*\lit{\dots Remaining methods}*) }
\end{lstlisting}
\end{figure}


\subsubsection{Ptr}

\code{Ptr} provides access to the type it points to, as it is guaranteed to be non-\code{null}.
This is done through the \code{Deref} trait, which handles the \code{*} operator in Rust. Due to
auto-deref, we can now use \code{\&Ptr<T>} in place of a \code{\&T}. The definition of \code{Ptr},
a new of its methods, and its \code{Deref} implementation is shown in \cref{lst:def-ptr}. Node that
both \code{new} and \code{get_mut} are \code{unsafe} methods; \code{new} because we can not
guarantee that the address passed is valid, and \code{get_mut} because the data may be aliased.

\begin{figure}[ht]
  \begin{lstlisting}[style=Rust,label=lst:def-ptr,
  caption=Definition of \code{Ptr},
  escapeinside={(@}{@)},
  ]
pub struct Ptr<'a, T: 'a> { data: usize, _marker: PhantomData<&'a T> }
impl<'a, T> Ptr<'a, T> {
    pub(crate) unsafe fn new(u: usize) -> Self {
        Self { data: u, _marker: PhantomData, } }
    pub unsafe fn get_mut(&mut self) -> &mut T { &mut *self.as_raw() }
    fn as_raw(&self) -> *mut T { with_tag(*self, 0).data as *mut T }
    (@\lit{\dots Remaining methods}@) }
impl<'a, T> Deref for Ptr<'a, T> {
    type Target = T;
    fn deref(&self) -> &T { unsafe { &*(self.as_raw()) } } }
\end{lstlisting}
\end{figure}


\subsubsection{Tagging}

By having one canonical pointer type, we can define functions that are generic over all types
that supports conversion from and/or to \code{NullablePtr}. This is used in the functions for
pointer tagging, as well as the \code{cas} in \cref{lst:def-atomic} (the types \code{A} and
\code{B}). \cref{lst:tagging} shows some of the free functions for pointer tags that are generic
over different pointer types.

\begin{figure}[ht]
\input{listings/tagging}
\end{figure}

\code{ones(k)} returns the bit mask with the \code{k} lower bits set, and \code{TAG_BITS} is a
predefined number of bits allowed to use for tagging for any pointer. We convert from \code{P} to
\code{NullablePtr} with \code{.into()} \coderef{TA2}.  In \code{with_tag} \coderef{TA5} we need
to use \code{TryFrom}, which is a conversion trait that may fail. In CMR \code{Ptr<T>} implements
\code{TryFrom<NullablePtr>}, where the conversion fails if the \code{NullablePtr} is \code{null}. We
assert that this failure should never happen \coderef{TA9} with the rationale that if we converted
some type \code{P} into a \code{NullablePtr} and changed its tag, we should be able to convert back
to \code{P}, even though the conversion is not always possible in general.

\subsection{Free Functions}

Having looked at the types and their member functions we now look at the implementations of
important free functions.

We first look at the higher order function \code{without_reclamation}:
\begin{lstlisting}[style=Rust]
pub fn without_reclamation<R, F: FnOnce() -> R>(f: F) -> R {
    let lock = ALLOC_LOCK.lock();
    compiler_fence(SeqCst);
    let ret = f();
    compiler_fence(SeqCst);
    drop(lock);
    ret }
\end{lstlisting}
The function runs the given closure without having a reclamation pass happening in between.  The
function simply grabs the reclamation lock before executing; is it however important that the
overhead here is as low as possible, as this is used in other important functions. For this reason
CMR also has the \code{without_reclamation_repeat} function, with attempts to run the closure
without any synchronization; if a reclamation pass happened while running, we rerun the function.

With the ability to run arbitrary code without a reclamation pass happening in between we can
implement \code{guard}, which is \proc{Load-Atomic} (\cref{eq:load-atomic}).
\begin{lstlisting}[style=Rust]
pub fn guard<'a, T>(guard: &'a mut Guard<T>, a: &Atomic<T>) -> NullablePtr<'a, T> {
    without_reclamation_repeat(|| { let p = unsafe { a.load(SeqCst) };
                                    guard.inner = ptr::raw(p);
                                    p }) }
\end{lstlisting}
Since we guarantee that no pass happened in between reading the \code{Atomic} and protecting the
data it pointed to in the \code{Guard}, we know that the data is still valid.


Another important function is \code{alloc}, which allocates memory:
\begin{lstlisting}[style=Rust]
pub fn alloc<T: Trace>(guard: &mut Guard<T>, t: T) -> Ptr<T> {
    let ptr = alloc::alloc(t);
    guard.inner = ptr::addr(ptr);
    alloc::register(ptr);
    ptr }
\end{lstlisting}
Note that we do not need to use \code{without_reclamation} here, since the newly address is
protected by the \code{Guard} before being registered; recall from \cref{sec:impl-data} that only
registered allocations are subject for reclamation.




\subsection{Correctness}

We argue for the correctness of the primitives as presented with respect to the definitions from
\cref{ch:cmr}.


\begin{claim}
  \cref{def:load-atomic-no-reclamation} is achievable.
\end{claim}
\begin{proof}
  \code{guard} implements \proc{Load-Atomic} with the wanted semantics.
\end{proof}

\begin{claim}
  \code{Guard} satisfies \cref{def:guard}.
\end{claim}
\begin{proof}
  The \code{Guard} is constructed with \code{null}, and gets values from \code{Atomic}s using
  \code{cmr::guard}; the values read are roots.
  Using the \code{guard!} macro it is impossible to move the \code{Guard}.
\end{proof}

\begin{claim}
  \code{NullablePtr} satisfies \cref{def:nullable-ptr}.
\end{claim}
\begin{proof}
  The type does not expose any mutating methods, so it is immutable.
  Looking at the function \code{guard} we see that the \code{\&mut Guard} is mutably borrowed, and
  since the lifetime of the \code{NullablePtr} returned has the same lifetime, the \code{Guard} is
  borrowed for the lifetime of the \code{NullablePtr}
\end{proof}

\begin{claim}
  \code{Ptr} satisfies \cref{def:ptr}.
\end{claim}
\begin{proof}
  The type does not expose any mutating methods, so it is immutable.
  Since \code{Ptr} is the only type implementing \code{Deref} and no function return a \code{\&T},
  all accesses to \code{T}s must be though the \code{Ptr}.
\end{proof}


We argue that since the primitives defined in \cref{ch:cmr} are implemented with the defined
semantics the results from \cref{sec:cmr-correctness} holds for the Rust implementation of CMR.


\section{Snapshot\label{sec:impl-snapshot}}

For obtaining a snapshot of the process memory CMR utilizes a operating system features offered
by POSIX compliant systems: \emph{forking}.
Calling \code{fork()} makes a copy of the current process, called the \emph{child process}.
The return value of \code{fork()} determined whether we are in the child or parent process.
In the child process, only the thread that called \code{fork()} continues its execution. For this
reason, we need to perform some work before forking. Most importantly, the threads needs to tell
the reclaiming thread where to find their \code{Guard}s. To do this we use a second POSIX feature:
\emph{signals} (see \cref{sec:background-signals}).

\begin{figure}[ht]
  \begin{lstlisting}[style=Rust,label=lst:thread-signaling,
  caption=Thread signaling,
  ]
fn signal_threads_except_self() -> usize {
    let mut count = 0;
    let me = thread_id();
    let mut th = THREAD_HANDLERS.lock().unwrap();
    th.retain(|&th|
      if th == me { true }
      else { unsafe {
            let val = libc::sigval { sival_ptr: std::ptr::null_mut() };
            let r = libc::pthread_sigqueue(th as u64, libc::SIGUSR1, val);
            if r == 0 { count += 1; true }
            else { false } } });
    count }
\end{lstlisting}
\end{figure}

Using \gls{pthreads} signals we register a signal handler for the \code{SIGUSR1} signal with the
\code{sigaction} call, and the reclaiming thread signals all threads with \code{pthread_sigqueue}.
This is done through the Rust library \code{libc}, which provides Rust bindings to the C standard
library. The procedure for signaling all registered threads is shown in
\cref{lst:thread-signaling}. Here we actually do two things at once: in addition to signaling the
threads, we remove the thread handlers that we fail to signal. The procedure returns the number of
threads we successfully signaled, so the caller knows how many threads to expect being in the
signal handler. Pseudo code for the signal handler is shown in \cref{lst:signal-handler}.

\begin{figure}[ht]
  \begin{lstlisting}[
    style=Rust,
    numbers=left,
    numberstyle=\color{gray}\ttfamily{}SH,
    caption=Pseudocode for the signal handler used by CMR,
    label=lst:signal-handler,
  ]
id = sh_enter_counter.fetch_add(1)  (*\label{c:sh-reg}*)
write_out_data_to(thread_datas[id]) (*\label{c:sh-write}*)
sh_done_counter.fetch_add(1)        (*\label{c:sh-done}*)
while sh_frozen.load():             (*\label{c:sh-while}*)
    wait()                          (*\label{c:sh-wait}*)
sh_enter_counter.fetch_sub(1)       (*\label{c:sh-leave}*)
\end{lstlisting}
\end{figure}


We use \code{sh_enter_counter} to keep track of how many threads are present in the signal handler;
the reclaiming thread knows how many threads it successfully signaled, so it knows how many threads to
expect. \coderef{SH\ref*{c:sh-reg}} registers a threads presence, in addition to giving each thread
a unique index in the range $[0, n)$, where $n$ is the number of threads signaled. This is used
in~\coderef{SH\ref*{c:sh-write}}, where each thread writes out their guards and allocations into
the global vector \code{thread_datas}. We then register that we have written our
data~\coderef{SH\ref*{c:sh-done}}, and wait for the reclaiming thread to unfreeze
us~\coderef{SH\ref*{c:sh-wait}}. At last we register that we have seen that we are done
\coderef{SH\ref*{c:sh-leave}}, so that no thread risk being stuck in the next iteration of the
reclaiming procedure, waiting again on the \code{sh_frozen} flag.



\section{Reachability\label{sec:impl-reachability}}

Reachability analysis is a straight forward implementation of the \proc{Find-Reachable} procedure
from \cref{sec:cmr-overview}, and is shown in \cref{lst:impl-find-reachable}. We maintain one
\code{HashMap} \coderef{FR\ref*{c:fr-mk-seen}} for all blocks we have seen, and a \code{VecDeque}
\coderef{FR\ref*{c:fr-mk-queue}} for the queue of blocks we want to visit. For efficiency reasons
we write out the reachable set when we find a new block, instead of collecting up the blocks and
writing it in one iteration \coderef{FR\ref*{c:fr-write}}. This implementation has capped the
number of pointers a single type can write out to be 32 \coderef{FR\ref*{c:fr-buffer}}; while this
is not sufficient in the general case, most types only require one or two pointers.



\begin{figure}[ht]
  \begin{lstlisting}[
    style=Rust,
    numbers=left,
    numberstyle=\color{gray}\ttfamily{}FR,
    caption=Rust implementation of \proc{Find-Reachable},
    label=lst:impl-find-reachable,
  ]
fn mark_and_sweep(mut cursor: Cursor<&mut [u8]>, roots: Vec<TraitObject>) -> usize {
    let mut seen = HashMap::new(); (*\label{c:fr-mk-seen}*)
    let mut queue = VecDeque::new(); (*\label{c:fr-mk-queue}*)
    (*\lit{insert roots into \code{seen} and \code{queue}}*)
    let mut num_ptr = 0;
    let mut ptr_buffer: [TraitObject; 32] = unsafe { std::mem::zeroed() }; (*\label{c:fr-buffer}*)
    while let Some(to) = queue.pop_front() {
        let addr = to.data as usize;
        let t: &ptr::Trace = unsafe { ::std::mem::transmute(to) };
        (*\lit{write out \code{addr} to the \code{cursor}}\label{c:fr-write}*)
        num_ptr += 1;
        let n = t.write(&mut ptr_buffer);
        for i in 0..n {
            let (to, addr, vtable) = (*\lit{destructure \code{ptr_buffer[i]}}*)
            if seen.insert(addr, vtable).is_none() {
                queue.push_back(to); } } }
    num_ptr }
\end{lstlisting}
\end{figure}


\subsection{Trace\label{sec:impl-trace}}

Finding pointers in arbitrary data types might involve significant work since the size of the data
types can be arbitrarily large. In addition, memory might not be initialized, and false positives
might occur if we are not careful. Instead of scanning through the memory block linearly, CMR
defines the Trait \code{Trace}, which all data types that is stored in shared memory must
implement.  A type implementing \code{Trace} knows a bound on how many shared memory pointers it
contains, and can write these out to a buffer. For instance, a \code{Node} in a single linked list
contains only one pointer, namely its next pointer, which is trivial to write out.

The implementation of this uses \emph{Trait Objects} (\cref{sec:trait-objects}), which involves
dynamic dispatch. This solution is potentially expensive, as it may involve cache misses in the
I-cache, although the number of misses is limited by the difference in data types in shared memory,
which normally is smaller than in Rust memory. \cref{lst:trace} shows the \code{Trait} as well as a
sample implementation for a node in a linked list.  This implementation uses \emph{specialization}
(\cref{sec:specialization}) as the implementation of \code{Node}s containing data that itself is
\code{Trace} is different.

\begin{figure}[ht]
  \begin{subfigure}{0.5\textwidth}
    \input{figures/trace}
    \caption{Illustration of a \code{BTNode<String>}}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \input{figures/trace2}
    \caption{Illustration of a \code{BTNode<List>}}
  \end{subfigure}
  \caption{Generics influence the number of potential roots a type has, as shown here with a binary
  tree node \code{BTNode<T>}. The \code{String} does not contain a root, but a node in a linked
  list \code{LNode} does.}
\end{figure}

\begin{figure}[ht]
  \input{listings/trace}
\end{figure}


\code{Trace} contains default implementations of the two functions, such that primitive types can
easily implement it. \code{write} takes a buffer, writes all pointers to it as \code{TraitObject}s,
and returns the number of objects written. \code{count} gives an upper bound on the number of
pointers written. This is useful for collection types, like \code{Vec} or \code{HashMap}, which
also may contain pointers to shared memory.

\code{Node} is a standard node from a linked list, containing \code{data}, and a \code{next}
pointer. The implementation of \code{write} loads the \code{next} pointer~\coderef{T8}, which is
an \code{unsafe} operation, as there is no \code{Guard} protecting the pointer. This is safe in the
context of the reclaiming thread since the memory will be freed at earliest when we finish the reachability
analysis, and at that point we no longer read the memory. The implementation only writes out the
pointer if it is non-null; while this is not required for CMR to function, it simplifies the logic
in the reachability analysis.


\subsection{Destructors}

Since Rust uses the \gls{raii} pattern extensively, we would like to run the destructors of type
when we free memory of that type. However, due to constraints in the the type system, this has
shown to be difficult to implement. We would like to have a single function \code{foo<T>} that,
based on whether the generic type \code{T} implements \code{Drop} or not to run have two different
implementations. There is no implemented solutions in the type system that allows this.
See~\cite{rust-impl-overlap} for discussion on the topic.
The main difference between this and \code{Trace} is that CMR requires all types to implement
\code{Trace}, but implementing \code{Drop} is optional.



\section{Communication\label{sec:impl-communication}}

When \code{fork}ing the child process continues the thread of the parent process that called
\code{fork()}, such that it has access to everything that the original thread had.
As such, we don't need to communicate from parent to child. However, the job of the child process
is to run reachability analysis, and we do need its result. CMR uses \emph{memory map}
(\cref{sec:memory-map}) for \gls{ipc}\@, which is set up before the fork. Since we need to
know when the child is done writing its results, we write a marker word as the first word in
the memory map. Then we \code{fork()}. The child process does the reachability analysis, and
writes the result after marker in the memory map. When it is done writing, it overwrites the marker
with the number of elements written.

\begin{figure}[ht]
  \centering
  \input{figures/memmap}
  \caption{Illustration of \gls{ipc} through a memory map. $T_2$ in the parent process is the
  reclaiming thread, so $T_2$ is the one thread in the child process. Both processes have
  access to the same memory in the memory map.}
\end{figure}

In order to minimize the delay of the reclamation pass from the point of view of the user, we spawn
a background thread which handles the part of the reclamation performed after we \code{fork()}.
This ensures that no user thread has to wait for the child process to finish its reachability
analysis before going back to running application code.  After forking, the parent process
unfreezes the other threads, and sends all necessary data to the background thread. Note that the
\code{reclaim_lock} is not released, even though the thread is exiting the procedure. The lock is
only released when the background thread is fully done with the reclamation pass.


\section{Complications\label{sec:impl-complications}}

A number of implementation complications arose while developing CMR\@. We look at a few of them
here.

\subsection{Allocation Lock\label{sec:alloc-lock}}

In order to protect programmers from deadlocks, POSIX defines a subset of functions as
\emph{async-signal safe}, meaning they are safe to call from a signal handler. Functions that are
async-signal safe includes \code{time()}, \code{open()}, and \code{mkdir()}, but it does \emph{not}
include \code{malloc()}. As such, allocation in signal handlers is not safe, and is a source of
deadlock bugs. This itself was not a large problem for CMR, as its signal handler did not require
any allocation. However, as threads are frozen by the reclaimer in a signal handler, it is also not
safe for the \emph{reclaimer} to call \code{malloc}, despite not being in a signal handler itself.
This is because some thread may be in the process of allocating memory, and have acquired a lock
internal to libc, right before being signaled. The thread is still holding the libc lock and is
frozen in its signal handler by the consolidator, which prevents \emph{all threads}, even those
oblivious to CMR, from allocating.

This problem is not solved properly by CMR, but its effects are mitigated by wrapping the general
allocator in Rust to go through yet another lock, the \code{alloc_lock}, which can be acquired by
the reclaiming thread.  In order to be more thread friendly we do not grab the global lock every
time we allocate; instead each thread flips a bit when they allocate, to signal to other threads
that they might be holding some internal lock. Upon exit they flip the bit back. When some other
thread wants to make sure that no thread is holding the lock, it flips a flag, and waits for all
threads to have their bit set to zero. This is effectively a read-write lock.

The locking scheme prevents most allocations of deadlocking, but not all. Rust uses \gls{pthreads}
internally for thread handling on Linux, which allocates internally, both in \code{spawn} and
\code{join}. The former may be circumvented by acquiring the allocation lock before calling it, but
this is no solution for the latter, since the thread may depend on allocating before exiting.


\subsection{SignalVec\label{sec:impl-signalvec}}

For performance reasons threads store their allocation in \gls{tls} in between reclamation passes
in a \code{Vec}.  The allocations are later collected in the threads signal handler when some
thread wants to reclaim memory, as the reclaiming thread requires access to all allocations in the
process. However, due to the asynchronous nature of signals we run into problems if a thread is in
the middle of some operation on the \code{Vec} when it is signaled, since the vector is copied and
\code{clear()}ed in the signal handler.

To handle this complication we made \code{SignalVec}, a \code{Vec} that supports asynchronous
\code{clear()}s. The implementation is a standard \code{Vec} implementation except that we use
\code{cas} to increment the \code{length} field of the \code{SignalVec}, such that we can detect
the case where \code{clear()} was called in the middle of \code{push}. Since we are writing to the
last element, we do not risk overwriting any values. The \code{SignalVec} is specifically designed
to only work in the exact use case that CMR requires.


\subsection{Thread Registration\label{sec:impl-thread-registration}}

Thread startup and shutdown has shown to be a difficult problem to handle, especially when
carefully managing when threads are allowed to allocate. Early attempts were made to automate this
using lazy initialization of thread local variables, but controlling allocations in these, or
guaranteeing the order of initialization was problematic. Testing with continuously checking whether
the thread was initialized in CMR methods showed that it imposed too much overhead for the strategy
to be viable.
