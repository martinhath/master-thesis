\chapter{Implementation}

In this chapter we look at the Rust implementation of CMR\@.  We look at four things: how thread
freezing is implemented (Section~\ref{sec:signals}), how reachability analysis is done
(Section~\ref{sec:reachability}), thread and process intercommunication
(Section~\ref{sec:thread-communication}), and how the primitives and operations as defiend in
Chapter~\ref{ch:cmr} are implemented (Section~\ref{sec:data-types}).


\section{POSIX Signals\label{sec:signals}}

\emph{Signals} is a process communication mechanism used by POSIX compliant operating systems.
\code{pthreads} (POSIX threads) also supports signaling for communication between threads in a
process. We utilize this in order to implement thread freezing, by registering a signal handler for
the signal \code{SIGUSR1}. Pseudocode for the signal handler CMR uses is shown in
Listing~\ref{lst:signal-handler}. The signal handler is registered with the \code{sigaction}
function, and threads are signaled with \code{pthread_sigqueue}.

\begin{figure}[b]
  \begin{lstlisting}[
    numbers=left,
    numberstyle=\color{gray}\ttfamily{}SH,
    caption=Pseudocode for the signal handler used by CMR,
    label=lst:signal-handler,
  ]
if is_in_cleanup:
    clean_up_and_return(£
id = sh_enter_counter.fetch_add(1£
write_out_data_to(thread_datas[id]£
sh_done_counter.fetch_add(1£
while sh_frozen.load(£:
    wait(£
sh_enter_counter.fetch_sub(1£\end{lstlisting}
\end{figure}

Due to a complication in which a threads shutdown procedure is initiated without the signal handler
being removed, we need to check if we are shutting down~\coderef{SH1}, as we do not have access to
the thread local storage, which we need. If we are shutting down we will not participate in the
rest of the handler, but clean up in order to avoid deadlocks~\coderef{SH2}.
We use \code{sh_enter_counter} to keep track of how many threads are present in the signal handler;
the reclaimer knows how many threads it succesfully signaled, so it knows how many threads to
expect. \coderef{SH3} registers a threads presence, in addition to giving each thread a unique
index in the range $[0, n)$, where $n$ is the number of threads signaled. This is used
in~\coderef{SH4}, where each thread writes out their guards and allocations into the global vector
\code{thread_datas}. We then register that we have written our data~\coderef{SH5}, and wait for the
reclaimer to unfreeze us~\coderef{SH6}.
\todo{Since we don't know that we have exited the handler after SH6, do we really need SH7??}



The signal handler is registered by a thread with a call to the \code{thread_activate} procedure,
which must be called before the thread is using CMR\@. \todo{bench automation of this in Guard or
something?}
The system has a fixed upper bound on the number of threads that may be active at any time, through
the \code{thread_datas} vector, which is pre-allocated with a fixed size \todo{check this out}.

Since a thread handler may have registered it leaving by decrementing \code{thread_counters[0]},
but then preempted before leaving the handler, CMR uses \code{pthread_sigqueue} instead of the more
standard \code{pthread_kill}, as \code{pthreads} may simply ignore a signal that is sent to a
thread when that thread is already in the signal handler for a given signal.
This is problematic, since the reclaimer keeps carefully track of where threads are in their
handler, and waits for all threads to reach certain checkpoints. If the reclaimer is lead to
believe that a thread just entered the handler when in fact it was just leaving, it will lead to a
deadlock.


\section{Reachability\label{sec:reachability}}

Reachability analysis is done through a standard mark-and-sweep algorithm. The reclaimer collects
all roots from all active threads, and looks through the memory of each data type that is pointer
to by the roots. If any data type contains a \mc{Guard} or \mc{Ptr}, the address is marked as seen,
and added to the frontier. When the frontier is empty, we have registered all reachable memory.
Listing~\ref{lst:find-reachable} shows the algorithm.

\begin{figure}[ht]
\begin{lstlisting}[
  caption=The algorithm used to find all reachable memory blocks,
  label=lst:find-reachable,
  frame=None,
  basicstyle=\normalsize\mdseries,
  columns=flexible,
  xleftmargin=15pt,
  numbers=left,
  keywordstyle={\bf},
  mathescape,
  commentstyle={\color{gray}},
  keywords={for,if,else,return,in,to,while,continue,break,output,not}]
$\textsc{find-reachable(Roots)}$
    Frontier = Roots
    Seen = Roots
    while mem = Pop(Frontier)
        for ptr in Ptrs(mem)
            if ptr not in Seen
                Push(Frontier, ptr)
            Insert(Seen, ptr)
    return Seen
\end{lstlisting}
\end{figure}

Finding pointers in arbitrary data types might involve significant work since the size of the data
types can be arbitrarily large, in addition to that memory might not be initialized, and false
positives. Instead of scanning through the memory block linearily, \note{should write somewhere why
we can assume that the ptr is the start of a block} CMR has a Trait called \code{Trace}, which all
data types that is in shared memory must implement.  A type implementing \code{Trace} knows a bound
on how many shared memory pointers it contains, and can write these out to a buffer. For instance,
a \code{Node} in a single linked list contains only one pointer, namely its next pointer, which is
trivial to write out.

The implementation of this uses \emph{Trait Objects} (Sec.~\ref{sec:trait-objects}), which involves
dynamic dispatch. This solution is potentially expensive, as it may involve cahce misses in the
I-cache, although the number of misses is limited by the difference in data types in shared memory,
which normally is smaller than in Rust memory.

\begin{figure}[t]
  \begin{lstlisting}[caption=Definition of the \code{Trace} trait and a sample implementation for
  a linked list node. The impementation uses \emph{specialization} (Section~\ref{sec:specialization}) as the
  implementation of \code{Node}s containing data that itself is \code{Trace} is different.,
  numbers=left,
  numberstyle=\color{gray}\ttfamily{}T,
  ]
pub trait Trace {
    fn count(&self) -> usize { 0 }
    fn write(&self, &mut [TraitObject]) -> usize { 0 }
}
pub struct Node<T> {
    data: ManuallyDrop<T>,
    next: Atomic<Node<T>>,
}
impl<T> cmr::Trace for Node<T> {
    default fn count(&self) -> usize { 1 }
    default fn write(&self, slice: &mut [TraitObject]) -> usize {
        let p = unsafe { self.next.load(SeqCst) };
        if !p.is_null() {
            slice[0] = ptr::trait_object(p);
            1
        } else {
            0
        }
    }
}\end{lstlisting}
\end{figure}

\code{Trace} contains default implementations of the two functions, such that primitive types can
easily implement it. \code{write} takes a buffer, writes all pointers to it as \code{TraitObject}s,
and returns the number of objects written. \code{count} gives an upper bound on the number of
pointers written. This is useful for collection types, like \code{Vec} or \code{HashMap}, which
also may contain pointers to shared memory.

\code{Node} is a standard node from a linked list, containing \code{data}, and a \code{next}
pointer. The implementation of \code{write} loads the \code{next} pointer~\coderef{T12}, which is
an \code{unsafe} operation, as there is no \mc{Guard} protecting the pointer. This is safe in the
context of the reclaimer since the memory will be freed at earliest when we finish the reachability
analysis, and at that point we no longer read the memory. The implementation only writes out the
pointer if it is non-null. While this is not required for CMR to function, it simplifies the logic
in the reachability analysis.




\section{Communication\label{sec:thread-communication}}
\todo{rename this section.}

In order to minimize the delay of the reclamation pass from the point of view of the user, we
employ a background thread which handles a part of the work after we \code{fork}. This ensures that
no user thread has to wait for the child to finish its reachability analysis before going back to
running application code.

The reclaimer goes through the list of threads frozen in the signal handler, and reads their
\mc{Guard}s, which includes information of the type that is pointed to. Then we set up the memory
mapped area, and write a \emph{marker} word in the first position, as a communication channel
between the child and the parent process: when this word changes we know that the child is done
with its work. The memory mapped area as well as new allocations are send to a background thread
that waits for the marker word to change.

\todo{must move mmap to above first use}
The child process performs the reachability analysis, by leveraging the \code{Trace} trait. After
the child process has completed the reachability analysis, it returns the set of reachable
addresses to the parent process through a \emph{memory mapped} area (Sec.~\ref{sec:memory-map}).  A
new area is set up on each reclamation iteration, using the \code{mmap} system call.  When
finishing the reachability analysis, it writes the number of reachable blocks in the first
position, overwriting the marker.





\section{Data Types\label{sec:data-types}}

In this section we look at the concrete Rust implementation of selected data types and operations,
and argue for their correctness.

\subsubsection{\mc{Guard}}

\begin{figure}[p]
  \begin{lstlisting}[caption=Excerpt of \mc{Guard}s definitions]
struct Guard<T> {
  ptr: usize,
  _marker: PhantomData<T>,
}
impl<T: Trace> Guard<T> {
    pub fn register(&mut self£ {
        ROOTS.with(|r| {
            let mut v = r.borrow_mut(£;
            v.push(GuardPointer::from_guard(self££
        }£;
    }
    ...
}\end{lstlisting}
\end{figure}

The \mc{Guard} is implemented as a single word, in addition to an empty type (the
\code{PhantomData}) as Rust \emph{requires} generic types to be used. \mc{Guard}s aren't normally
constructed directly (\todo{non movable types somewhere}), but rather declared with the
\code{guard!} macro, which constructs it and calls \code{Guard::register}. Since we need to keep
track of type information dynamically, we construct a \code{GuardPointer} which does exactly this,
and pushes it onto a thread local \code{Vec}, \code{ROOTS}.
It is also possible to construct a \mc{NullablePtr} from the \mc{Guard}.

\subsubsection{\mc{Atomic}}

\mc{Atomic} is mainly a wrapper around Rusts \code{AtomicPtr}, although the internals differ
slightly. CMR defines its own type so that we can defide on the return types of certain functions.
We include the definition of the \code{struct}, as well as \code{cas}, the compare-and-swap
operation, in which we utilize some Traits from the Rust standard library to convert between types.
\todo{write a little here}

\begin{figure}[p]
  \begin{lstlisting}[caption=Excerpt of \mc{Atomic}s definitions]
pub struct Atomic<T> {
    data: AtomicUsize,
    _marker: PhantomData<T>,
}
impl<T> Atomic<T> {
    pub fn cas<'a, A, B>(&self, a: A, b: B, ordering: Ordering) -> Result<A, NullablePtr<'a, T>>
    where
        T: 'a,
        A: Into<NullablePtr<'a, T>> + ::std::convert::TryFrom<NullablePtr<'a, T>>,
        <A as ::std::convert::TryFrom<NullablePtr<'a, T>>>::Error: ::std::fmt::Debug,
        B: Into<NullablePtr<'a, T>>,
    {
        let old = raw(a);
        let new = raw(b);
        let ret = self.data.compare_and_swap(old, new, ordering);
        if ret == old {
            Ok(A::try_from(NullablePtr::new(ret)).unwrap())
        } else {
            Err(NullablePtr::new(ret))
        }
    }
    ...
}

\end{lstlisting}
\end{figure}

\clearpage
\vspace{2cm}


The key idea of the implementation is to use an operation known as \emph{forking} to obtain a
snapshot of the entire memory space of the process. Having this we can identify the roots, and run
reachability analysis, knowing that nothing will change while we are looking.

Consolidation starts by sending all running threads a \emph{signal}, causing them to jump to a
\emph{signal handler}. The signal handler registers that the thread has been signaled, such that the
garbage collection pass is detectable. Then the thread writes out the address of a thread local
list of allocated addresses, such that the consolidator can collect all addresses that has been
allocated since the last consolidation. At last, the threads wait for the consolidator to say that
they may return to their execution. \note{why is this required?}

\note{Add implementation details here}

  \code{WAS\_SIGNALED} is a thread local flag that is
  set to \code{true} in the signal handler. Note that this function does not support being called
  recursively.
\begin{figure}[ht]
  \begin{lstlisting}[numbers=left,numberstyle=\color{gray}\ttfamily{}A,caption=Pseudocode of $atomic$]
fn atomic(f: F):
  loop:
    WAS_SIGNALED = false
    let ret = f()
    if not WAS_SIGNALED: return ret
\end{lstlisting}
\end{figure}

\begin{theorem}
  If \code{f} does not itself call \code{atomic} then \code{atomic} satisfy
  Definition~\ref{eq:atomic}.
\end{theorem}
\begin{proof}
  \code{WAS\_SIGNALED} is set to \code{false} in \code{A3}, so if it is observed to be
  \code{true} in \code{A5} the signal handler must have been executed. Since only the consolidator
  signals any thread, it means that there was a consolidator in this time interval. We are only
  returning from the function if \code{WAS\_SIGNALED = false}, so if we return \code{f} was
  successfully called without overlapping with a pass.
\end{proof}
Note that it is possible that the consolidator was initiated before entering the \code{atomic}
function, but that they only got execution time after \code{A3}.
\begin{lemma}
  If the consolidator is lock-free, then \code{atomic} is lock-free.
\end{lemma}
\begin{proof}
  If we loop, there is a consolidator. Since the consolidate process has a finite number of steps
  and is lock-free, it will either make progress, or some other thread is making progress. In
  either case, the system makes progress.
  \note{this is a terrible proof}
\end{proof}

It is important that the function given to \code{atomic} can be called multiple times without
breaking. The most useful case for \code{atomic} is a \code{load/store} store pair, so this is
usually the case.
