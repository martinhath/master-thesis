\chapter{Usage of CMR\label{ch:usage}}

In this chapter we look at usage code for CMR\@. The goal of this chapter is twofold: we mainly
want to look closer at how the abstractions that CMR provides are used and how difficult they are
to use; we also believe that showing the implementations of the data structures we can further
reason about the performance characteristics and pitfalls for the results obtained in
\cref{ch:results}.

We have implemented four data structures: a stack, a queue, a list, and a hashmap, and the
implementations will be considered in sequence.


\clearpage


\section{Lock-free Stack\label{sec:usage-stack}}

\begin{figure}[b]
\centering
\input{figures/stack}
\caption{$T\sb{1}$ and $T\sb{2}$ both tries to swap the \code{head} pointer towards their
node.}
\end{figure}

We begin by looking at an implementation of a concurrent stack, which is arguably the simplest
concurrent data structure. The stack is the well known Treiber Stack
from~\cite{treiber1986systems}.

The definitions of the \code{Stack} and \code{Node} structs and the two most important operations
on a stack, \code{push} and \code{pop}, is shown in \cref{lst:stack-ops}. We look at each one in
turn. Construction of the stack is omitted for brevity, since an empty stack just has a \code{null}
pointer as its top node.

\begin{figure}[ht]
\input{listings/stack-ops}
\end{figure}

\subsection{Push}

\code{push} allocates the stack node itself, so it takes the value we want to push onto the stack
\coderef{ST5}. We start out by declaring two \code{Guard}s \coderef{ST6}: one for the new node we
allocate, and one for the head of the stack. We must protect the head of the stack, since the node
may be removed after we read its address, and we would have a dangling pointer.  Next we allocate a
new \code{node} \coderef{ST7}, which is done outside the retry loop so that we only have to
allocate one time per call to \code{push}. Now we enter the retry loop, which we repeat until we
succeed in changing the top pointer of the stack to our new node.
The top node is read \coderef{ST8}, and the \code{next} pointer of the new node is set to the head
\coderef{ST9}. If we succeed of changing the \code{top}  pointer of the stack to our new node, we
break out of the loop and return \coderef{ST10}. If not, we retry until we do.


\subsection{Pop}

\code{pop} is similar to \code{push}. We declare two \code{Guard}s \coderef{ST13}, but this time
they are for the first and second node in the stack. We read the \code{top} pointer \coderef{ST14},
and return from the function if it is \code{null} using the \code{?} Rust operator. We then read
the next pointer of the node \coderef{ST15}; here the \code{null} case is the same as the
non-\code{null} case. We try to swap the head pointer from the first to the second node
\coderef{ST16}; if we fail we restart, and if we succeed we move out the \code{Node} from the
\code{Guard}. This is an \code{unsafe} operation, as the type is copied out of its original place,
effectively aliasing it. At last, the data is returned.

As an example of why reading and returning the node data is \code{unsafe} in the general case,
consider two threads $T\sb{1}$ and $T\sb{2}$ using a \code{Stack<Box<T>>}. $T\sb{1}$ is looking at
a node $n$, and $T\sb{2}$ is \code{pop}ping $n$ from the stack, getting the \code{Box<T>} back from
it. Now $T\sb{2}$ \code{drop}s the \code{Box}, which frees the pointer. If $T\sb{1}$ decides to
look at the data in $n$, it will dereference a freed pointer, which is a use-after-free
(\cref{def:use-after-free}). Despite being \code{unsafe} in the general case, it is safe for the
implementation of the stack as presented, since no operation on the stack looks at the data of a
node, except in \coderef{ST17}, where only one thread may be for any given node, since we succeed
the \code{cas} operation.




\section{Lock-free Queue\label{sec:usage-queue}}


The queue implemented is based on the well known Michael-Scott Queue from~\cite{michael1996simple}.
The idea behind the queue is to have a sentinel node as the first node of the queue in order to
avoid difficult edge cases when the queue is empty. The sentinel node is the grayed out node in
\cref{fig:msqueue}.

The \code{Node} and \code{MsQueue} struct definitions are omitted, as they are very similar to
those of the \code{Stack}. The main difference is that in the \code{Queue} we maintain both the
\code{head} and \code{tail}. The following invariants hold for the \code{Queue}: \code{head} is
never \code{null}, at any instant \code{tail} is either the last, or second last node in the
queue.

\code{push} is shown in \cref{lst:msqueue}; \code{pop} is omitted due
to its similarity with \code{Stack::pop}.

\begin{figure}[ht]
\input{listings/msqueue}
\end{figure}

We start out by declaring three \code{Guard}s \coderef{MS3}: one for the new node, one for the
current tail, and one for the tails \code{next} node, which may be present.  We load \code{tail}
\coderef{MS5}, and its \code{next} pointer \coderef{MS7}.  Since the Michael-Scott queue is always
non-empty, we know that the \code{head} is non-\code{null}, and it is therefore safe to promote the
\code{NullablePtr} to a \code{Ptr} using \code{.unwrap()}.  If the next pointer is non-\code{null}
the node we believed was the tail was not the tail after all. We try to swing \code{tail} from the
node we read, to its next node \coderef{MS8} before restarting.  If the tail was \code{null} we try
to \code{cas} its next field from \code{null} to our new node \coderef{MS9}. If we succeed, we
\code{cas} the tail to our node and exit. If we fail, we restart.  Note that we do not check the
results of the the \code{cas} where we set the tail to the node we just inserted; if this operation
fails, it just means that some other thread came along and noticed that \code{tail} was not the
real tail, and \code{cas}ed it to the last node \coderef{MS8}.

\begin{figure}[ht]
\centering
\input{figures/queue}
  \caption{The Michael-Scott Queue. The first node in the queue is a sentinel
  node.\label{fig:msqueue}}
\end{figure}



\section{Lock-free List\label{sec:usage-list}}

Michael introduced a concurrent List in~\cite{harris2001pragmatic}, which this implementation is
based upon. The list is similar to the Stack from \cref{sec:usage-stack}, but we support more
operations than \code{push} and \code{pop}, including queries and removals, and insertions into
arbitrary points in the list. Definitions of \code{List} are very similar to that of the
\code{Stack} and \code{Queue}, and is therefore omitted.

Having arbitrary \code{insert} and \code{remove} opens for a problem known as \emph{double-remove},
shown in \cref{fig:list-remove}. Let there be two threads in the system $T\sb{1}$ and $T\sb{2}$,
and let A, B, and C be three consecutive nodes in the list. If $T\sb{1}$ wants to remove the B
node, there is a small window in which $T\sb{2}$ may insert a new node, X, between B and C. When
$T\sb{1}$s \code{cas} operation succeeds --- note that \code{A.next} was not touched by $T\sb{2}$
--- it will accidentally swing the pointer past the new node X without noticing. This is a variant of
the ABA problem (\cref{sec:aba-problem}).

\begin{figure}[ht]
\centering
\input{figures/list-remove}
\caption{Double removal with \code{List::remove}\label{fig:list-remove}.}
\end{figure}

A solution to this problem, as shown in eg.~\cite{michael2002high}, is to exploit memory alignment
on modern CPU architectures: \code{struct}s are \emph{aligned} in memory, meaning their address is
a multiple of some power of two. This causes the least significant bits of their address to always
be zero; bits that may be used for other purposes. We use the least significant bit in the
\code{.next} field in a node for a \emph{tag}\footnote{Now we finally understand why CMR supports
pointer tagging from \cref{sec:cmr-pointer-tagging}}, signaling that the node is logically deleted,
and should not be acted upon. To see how this helps the problem as shown above, $T\sb{1}$ would
start out the deletion process of B by calling \code{cas(B.next, C, with_tag(C, 1))}. Should this
fail, $T\sb{1}$ can just read \code{B.next} again, and retry. When it succeeds, it may try to
\code{cas} \code{A.next} over B to C. Now $T\sb{2}$ realizes that it should not insert X between B
and C, since it reads the tag of B, realizing that it was deleted.


\subsection{The Entry API}

Many of the most interesting operations on the List involves iterating through the list. Due to the
ownership and lifetime rules that Rust imposes, it may be tricky to implement typical iteration
since due to the pointer juggling and the lifetime issues that arises. For this reason, the API
uses an abstraction for iterating through the list: \code{Entry}.

\begin{figure}[ht]
\input{listings/list-entry}
\end{figure}

An \code{Entry} is like a pointer into the list, which can \code{step()} to the next node, get a
pointer to the \code{current()} node, \code{remove} the current node, \code{insert_between} two
nodes, and find nodes which data satisfies arbitrary closures \code{Fn(T) -> bool}.  Since there is
some overhead in declaring a \code{Guard}, \code{Entry} contains references to \code{Guard}s rather
than the \code{Guard}s themselves. This makes constructing a \code{Guard} nearly free.  Another
implication of this is that \code{Entry} is movable in memory (as \code{Guard} is not), which can
be practical.

This indirection simplifies many operations, and we barely need to deal with lifetime and ownership
issues, although it almost requires \gls{nll} (\cref{sec:nll}) to use, since we still need to
handle the pointer management inside the \code{Entry}s methods.

\begin{figure}[ht]
\input{listings/list-foreach}
\end{figure}







\section{Lock-free Hash Table\label{sec:usage-hashmap}}

The hash table is a versatile and popular data structure, and is widely used due to its fast
operations, which includes queries, insertions, and removals. The hash table is also a more
interesting data structure to look at from a concurrency perspective, as it has the potential to
scale much better, since not all operations is on the same memory; in comparison a queue only has
two locations, namely the front and back, which are of interest. Multiple inserts may be done
concurrently in a hash table without touching the same memory at all; this greatly increases the
gain from having multiple threads.

Lock-free hash tables are interesting for the same reasons as regular hash tables. Despite the
interest, designing a concurrent hash table turns out to be a difficult problem.
Usually the problems revolve around \emph{resizing} the hash table. A common approach to
implementing hash tables is to have an array of \emph{buckets} in which the elements resides. Keys
which hashes share some property (eg\. a common prefix or suffix) may be put in the same bucket.
When the \emph{load factor} --- the ratio of elements in the table to the number of buckets --- is
too large, we increase the number of buckets: we resize the hash table. The hash table implemented
does not deal with this problem: we have a fixed number of ``buckets'', although it is possible to
extend the implementation to better handle large load factors by recursively constructing a new
sentinel array to handle the next $n$ bits of the hash.
The size of the array in the implemented hash table is $2^{20} = 1048576$.


\subsection{Split-Ordered List}

We start by describing the \emph{Split-Ordered List}, which were introduced
in~\cite{shalev2006split}.  The list is a regular linked list where the nodes are ordered by the
\emph{reverse hash} of the value in the node. The list also contains \emph{sentinel nodes}, nodes
without meaningful data, but which marks the beginnings of a bucket in the hash table.  By making
the number of buckets $b=2\sp{k}$ we can double $b$ when the load factor is too high, and insert
one more sentinel node between each of the nodes already present; this effectively differentiates
between \emph{one} new bit of the reverse hash.  See \cref{fig:reverse-bits} for an illustration of
the numbers $[0,15]$ ordered by their bit-reverse. Note that when adding numbers up to the next
power of two no two inserted numbers are consecutive; they spread nicely.

\begin{figure}[ht]
  \centering
  \input{figures/bit-reversal}
  \caption{The numbers $[0, 15]$ ordered by their bit-reversal\label{fig:reverse-bits}}
\end{figure}

Using the Split-Ordered List we can implement a concurrent hash table by having an array of
pointers to sentinel nodes, and a ``size'' of the bucket array. If a sentinel pointer is
\code{null}, then the node is not yet in the table. When inserting a new element into the table, we
first find the sentinel node that precedes the node we want to insert (the \emph{parent}); this is
known, since we know the ordering of the nodes in the list --- the reverse hash. However, due to
the resizing method, the parent may not have been inserted yet. If not, we can simply recurse on
the insertion method, and insert the parent first. Then we jump to the preceding sentinel node, and
iterate through the list, finding the place in which our new node should be. Assuming a small load
factor, this is a fast operation.

\begin{figure}[ht]
\centering
\input{figures/hashmap}
\caption{The Split-Ordered List. Node labels shows the \code{hash} and its reverse in
parenthesis.\label{fig:split-order-list}}
\end{figure}

\cref{fig:split-order-list} shows the split-ordered list with a table size of $4$. The nodes in the
list are ordered by the reverse of their hash (shown in parenthesis). Given a node \code{n}, we
find the sentinel node that should precede it in the list by taking \code{hash(n) \% table_size}.
Note that this is not the reverse hash. For instance, inserting a node where \code{hash(n) == 7},
we look in bucket \code{7 \% 4 == 3}, and iterate from sentinel node 3. It is only in the iteration
where we insert our new node that we use the reverse hash.  Inserting a node where \code{hash(n) ==
10}, we would get \code{bucket == 2}, which is \code{null}, so we need to insert the sentinel node
first. This sentinel node would be inserted in between the \code{h} and \code{e} node, since
sentinel nodes precede data nodes with the same reverse hash.

Next we look at the most important operations in the hash table: \code{contains} and \code{insert}.
Removals are similar to in the List; we remove the data node from the list. Sentinel nodes are
never removed. While this increases the memory usage of hash tables, it does not reduce the
performance of lookups since the number of sentinel nodes we need to look at does not change.

\subsection{Contains}

\cref{lst:hashmap-contains} shows the implementation of \code{HashMap::contains}. The
implementation of utility functions such as \code{bucket_and_revhash} are omitted for brevity.  We
find the \code{parent} node \coderef{HC4}, and use the \code{Entry} API from \code{List}
\coderef{HC6} to look for the first node which hash and key is the same; if we encounter a node
which hash is more than our node, we know that we have gone too far. \code{Entry::seek_with_opt}
lets us break out of the search early by returning \code{None} \coderef{HC10}. If we find a node
with both the right hash and the right key, we return \code{Some(true)} from the
closure \coderef{HC11}, and \code{seek_with_opt} returns \code{Ok}. If we get back \code{Ok}, the
search succeeded, so we return \code{true}, and \code{false} otherwise.
\input{listings/hashmap-contains}


\subsection{Insert}
\code{HashMap::insert} is more complicated, as there are multiple things that can go wrong, and
that some operations require cleanup. \cref{lst:hashmap-insert} shows the implementation of
\code{insert}. Due to the complexity of the method, we have omitted certain sections of the code.
The omitted code is either similar operations to previously shown methods, or explained in the
text.

\input{listings/hashmap-insert}

We start out by hashing the \code{key}, finding the reverse hash \coderef{HI3} and the bucket of
the sentinel node, and a pointer to the node is acquired \coderef{HI4}. We declare five (!)
\code{Guard}s \coderef{HI5}, and \code{alloc} our new node \coderef{HI7}.
Next we make our \code{entry} from the sentinel \coderef{HI9}, and find the correct place to put
our new node \coderef{HI10}. The new node is put before any other nodes with the same hash, but
after the sentinel node, should their hashes be the same. We insert the new node in front of the
old nodes so that other threads will see the most recently updated node first. The result of this
operation has three cases:
\begin{enumerate*}[1) ]
  \item we fail with \code{Empty} which means we got to the end of the list, and is handled by
    inserting the new node at the end of the list  \coderef{HI13},
  \item we fail with another failure case and restart \coderef{HI15}, and
  \item we succeed and actually insert our new node into the list \coderef{HI16}, where we, again,
    restart upon failure.
\end{enumerate*}

After insertion we must check for other nodes with the same key, since there should only be one
entry for any given key in the map \coderef{HI17}. This is done by making a new \code{Entry} with
the new node, \code{step}ping once, so that the \code{current} node is not our new node, and
\code{delete()} any node that has the right key.  When we hit a node which hash is more than our
own, we are done.


\subsection{Remove}
\code{HashMap::remove} is, in comparison to \code{insert}, simpler.
Finding the sentinel is similar to \code{insert} \coderef{HR3-HR7}, but in \coderef{HR8} we use
\code{seek_with_opt} which allows for early termination of the search, since we should stop if we
reach a node with a larger hash than the one we want to remove. We test the result of the search
\coderef{HR14} and branch appropriately, and call \code{Entry::delete} \coderef{HR18} if we found
the node we are looking for. Only if we succeed in removing the node we break the loop.

\input{listings/hashmap-remove}

An important detail about \code{Entry::remove} is that the actual \code{cas} to remove the node
from the list does not need to be successful for the operation to be considered as such; it is
sufficient for the node to be tagged as removed. This is due to the fact that if the node is tagged
as removed, any thread \code{step}ping over it will remove it.
