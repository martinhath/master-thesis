\chapter{CMR}

We have named the system \emph{CMR}, short for \emph{Concurrent Memory Reclamation}. The system is
implemented as a Rust library \code{cmr}. We have also implemented four data structures, a stack,
queue, list, and hasmap, in the \code{cmr-data-structures} library, which uses \code{cmr}
internally for memory reclamation.

This chapter is organized as follows:
Section~\ref{sec:cmr-overview} gives an overview of the system as a whole, and defines the problem
we want to solve.
Section~\ref{sec:cmr-primitives} defines the primitives of the system, how they interact, and
proves their correctness.
\todo{bla}

\section{Problem Definition}

We define an abstract model of the system, and prove its correctness.
The computational model we are working with is the RAM machine, and assume that
the reader is familiar with it\footnote{\todo{Have def.\ in background?}}.

We start by defining some central concepts.
Memory $M$ is the set of all addresses in the address space of the machine.
It is a disjoint set $M = A \cap F$ where $A$ is the set of allocated memory, and $F$ is the
remaining of the memory space.
A \emph{block} is a tuple $(addr, size)$ and represents the memory segment $\left[addr, addr +
size\right)$.
We call memory that is in an allocated block \emph{valid memory}.

In Rust, most memory management is handled automatically by the compiler. CMR utilizes this by
distinguishing between \emph{Rust memory} and \emph{Shared memory}. Rust memory is all memory that
is managed by the compiler, for instance through smart pointers. Shared memory is the remaining
memory, which is managed by CMR\@. Note that there is a thin line in between the two types: types may
be handled by CMR, but they themselves may contain smart pointers which is then handled by Rust.
For instance, a node in a linked list implemented using CMR may contain data that contains a smart
pointer. When the node is freed, its destructor is ran, and the smart pointers cleanup is handled
just as if it was not in shared memory (see Figure~\ref{fig:rust-shared-mem}).

Since Rust manages Rust memory, we only need to do reachability queries in the shared memory
subset. For many applications, this is a much smaller space than the total memory. It is also
possible to have the data types that are referenced from shared memory but stored in Rust memory
(like the binary tree in Figure~\ref{fig:rust-shared-mem}) know whether they have pointers to
shared memory, so that we don't have to scan through the strucutre, as it may be arbitrary large.


\begin{figure}
  \centering
  \input{figures/rust-shared-mem}
  \caption{Example of memory layout showing Rust memory (beige) and shared memory (red). Types in
  shared memory may contain pointers to Rust memory, and vice versa.\label{fig:rust-shared-mem}}
\end{figure}

\subsection{Memory Hazards}

There are a number of possible hazards when managing memory manually. We first define three
hazards:

\begin{definition}[invalid-read]
  Memory that has never been allocated is read.
\end{definition}

\begin{definition}[use-after-free]
  Memory that was allocated and then freed is read.
\end{definition}

\begin{definition}[double-free]
  A block is freed twice without being allocated in between.
\end{definition}

invalid-read is the least frequent of the three, as it requires the programmer to conjure a pointer
out of thin air, since it has never been allocated in the system.\ use-after-free is the most
hazarous of the three, as program behaviour is often undefined when freed values are read \todo{ref
UB}; in many language implementations undefined behavious means that the entire program is illegal,
and one cannot assume anything about its behaviour.\ double-free is technically not a memory
hazard, as the operating system can check for the validity of pointers that are freed. This is
often not done in practice, and POSIXs definition of \code{free} states that it is undefined
behaviour to pass a non-allocated pointer to \code{free}.  \todo{check this.}

We will show that CMR guarantees that neither of the three hazards is possible in safe Rust.

\section{Overview\label{sec:cmr-overview}}

The high level idea of the system is for the consolidator to have easy access to all roots in every
thread. With this information, the problem of identifying garbage is equivalent to reachability
analysis in a graph in which the vertices are data types in the program and the edges are pointers.
 Having this, we can
identify the reachable segments $R \subseteq M$ and the garbage $G = M \setminus R$.

\begin{figure}[ht]
  \centering
  \begin{subfigure}{0.45\textwidth}
    \begin{lstlisting}
a = Node { value = 4, next = null }
b = Node { value = 8, next = a }
list = [a, b, 3]
    \end{lstlisting}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.45\textwidth}
    \input{figures/graph-reachability}
  \end{subfigure}
  \caption{Code sample (left) with possible heap layout (right). If the black filled node is the
  only root, the black nodes are reachable, and the gray nodes are not. Note that one node (z)
  points to a reachable node, but is itself not reachable.}
\end{figure}

Performing the reachability analisys is not straight forwards, even when we have all roots in the
system. Consider a mark-and-sweep approach, where we follow pointers and keep track of memory
locations that we have seen before. Since we are running a concurrent system, pointers might be
updated while we scan, so that two pointer values might be swapped after looking at either of them,
making the other value invisible to the system, and causing memory to be registered as unreachable,
when it is not. See Figure~\ref{fig:pointer-swap} for an example.

\begin{figure}[ht]
  \centering
  \input{figures/pointer-swap}
  \caption{Illustration of how mutation in the reachability graph can make a block $b$ appear as
  non-reachable. After we have looked at the roots left child, but before reading its right, the
  nodes child pointers are swapped. Since we cannot detect this (the two pointers could have been
  the same), we see $a$ twice and do not see $b$.\label{fig:pointer-swap}}
\end{figure}

In order to handle mutation problems, we obtain a snapshot of the entire processes memory by
freezing all threads, reading their roots, and forking the process. Thus, we have a snapshot of
the entire memory of the program, in which we also have all roots. Now the reachability analysis is
simpler, since there will be only one thread in the forked process, namely the garbage collecting
thread. Listing~\ref{lst:cmr} shows pseudocode for both the reclaiming thread and the other threads
for this procedure.

\begin{figure}[ht]
  \begin{subfigure}{0.45\textwidth}
    \begin{lstlisting}
CMR():
    freeze_threads()
    wait_for_writes()
    read_guards()
    fork()
    unfreeze()
    for addr in unreachables():
        free(addr)
    \end{lstlisting}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.45\textwidth}
    \begin{lstlisting}
on_freeze():
    write_roots()
    register_done()
    wait_for_unfreeze()
    \end{lstlisting}
  \end{subfigure}
  \caption{Pseudocode of CMR\@. The leftmost code is for the thread that runs the reclamation pass,
  and the rightmost code is other threads in the system.\label{lst:cmr}}
\end{figure}


\todo{define ``Rust memory'' and shared memory}

\section{Primitives of CMR\label{sec:cmr-primitives}}

The central data type to achieve this is \code{Guard}. A \code{Guard} is an object in which a
pointer to shared memory is stored. All pointers to shared memory are stored in a Guard. By having
access to all \code{Guard}s, CMR have access to all roots. \code{Guard}s are similar to hazard
pointers (Section~\ref{sec:hazard-pointers}), except that no thread synchronization is performed
when making new or updating existing \code{Guard}s, which reduces the overhead significantly.

CMR has four types that are essential to understanding how we manage safe access to shared memory:
\emph{Guard}, \emph{Atomic}, \emph{NullablePtr}, and \emph{Ptr}. All types are generic over the
type of the data they protect; this is omitted for brevity. We look at each type in turn.

\begin{definition}[Guard]
  A \emph{Guard} is an object that contains a \emph{root}. The Guard is non-movable in memory.
  All roots are stored in Guards.
\end{definition}

\begin{definition}[Atomic]
  An \emph{Atomic} is a pointer variable that provides safe concurrent access.
\end{definition}

\begin{definition}[NullablePtr]
  \emph{NullablePtr} is an immutable pointer that may be $\bot$. It is obtained through a Guard.
  When a NullablePtr $p$ is obtained from a Guard $g$, $g$ is immutable thoughout the
  lifetime\footnote{We use the same meaning of lifetime as Rust (Section~\ref{sec:rust-lifetimes})}
  of $p$.
\end{definition}

\begin{definition}[Ptr]
  \emph{Ptr} is an immutable pointer that may \emph{not} be $\bot$. Its semantics are similar to
  that of NullablePtr, but the two are distinct types for simplification of the null-case. All
  accesses to shared memory is through a Ptr.
\end{definition}

These four types are the building blocks of writing concurrent structures in CMR\@. All pointers
are stored in an Atomic, and loading an atomic yields a NullablePtr, which may be promoted to a
Ptr, if it is not null. The Ptr provides access to the data the pointer points to.
In addition to having the types, CMR defines a number of operations that acts on these types.
We look at each type in turn, and define their operations.

\subsection{Guard}
A Guard can be constructed with the initial value of $\bot$ with \emph{make-guard}
\begin{equation}\label{eq:make-guard}
  \text{make-guard\:::\:} () \to Guard
\end{equation}
It can also copy the value of another Guard with \emph{copy-guard}.
\begin{equation}\label{eq:copy-guard}
  \text{copy-guard\:::\:} (Guard, Guard) \to ()
\end{equation}


\subsection{Atomic}

Atomic is a regular atomic pointer variable, supporing operations such as \emph{store}, and
\emph{compare-and-swap}.
\begin{equation}\label{eq:atomic-store}
  \text{store\:::\:} (Atomic, NullablePtr) \to ()
\end{equation}
\begin{equation}\label{eq:atomic-cas}
  \text{compare-and-swap\:::\:} (Atomic, NullablePtr, NullablePtr) \to NullablePtr
\end{equation}

It is not safe to \emph{load} an atomic, as there is no guarantee that the
pointer read is protected by a guard. Instead, CMR defines \emph{load-atomic}, which loads an
Atomic into a Guard, and returns the value read as a NullablePtr:
\begin{equation}\label{eq:load-atomic}
  \text{load-atomic\:::\:} (Guard, Atomic) \to NullablePtr
\end{equation}

\subsection{NullablePtr}

The NullablePtr is just a convenience type in order to not have to handle the $\bot$ case of all
pointers. Whether the pointer is null or not can be checked:

\begin{equation}\label{eq:nullable-is-null}
  \text{is-null\:::\:} (NullablePtr) \to bool
\end{equation}

CMR also supports using the lower bits of a pointer to store extra information (a \emph{tag}). This
is useful for implementing deletion in linked lists, among other things.  The tag is read with
\emph{tag},
\begin{equation}\label{eq:ptr-tag}
  \text{tag\:::\:} (NullablePtr) \to int
\end{equation}
and a new NullablePtr can be constructed with a given tag using \emph{with-tag}.
\begin{equation}\label{eq:ptr-with-tag}
  \text{with-tag\:::\:} (NullablePtr, int) \to NullablePtr
\end{equation}
The actual address is obtained through \emph{addr}
\begin{equation}\label{eq:ptr-with-tag}
  \text{addr\:::\:} (NullablePtr) \to int
\end{equation}

\subsection{Ptr}

Ptr may be used in the place of NullablePtr, since is it just a special case of it. All functions
that take a NullablePtr can also take a Ptr.


\subsection{Other actions}

We also need a few other operations to make sure that the implementation of funcions are valid.
For instance, in load-atomic there is a window in between reading the atomic ptr and storing it in
the guard in which a reclamation pass may have happened. \emph{atomic} makes sure that this is
safe:
\begin{definition}\label{def:atomic}
  $\text{atomic\:::\:} (() \to T) \to T$ is a higher order function that runs a function without
  a reclamation pass happening during the functions execution.
\end{definition}


\clearpage





With these types and operations we are able to prove important properties of the system.

\begin{theorem}[Guard is valid]\label{thm:guard-valid}
  If a Guard is not $\bot$, it points to valid memory.
\end{theorem}
\begin{proof}
  \note{lol}
  Assume the Guard $g$ $\neq \bot$.
  The Guard has loaded its value from an Atomic $a$ using $atomic-load$.
We first show that $a$ is itself in valid memory. By induction:
\emph{Base case:} the Atomic resides in Rust memory, and is thus valid. \emph{Inductive case:} the
Atomic resides in shared memory, and thus accessed through a Ptr $p$.  This Ptr is protected by a
Guard $g\sb{2} \neq g$, since $g\sb{2}$ is immutable throughout the lifetime of $p$, and $g$ is
being changed. $g\sb{2}$ is valid by induction, so the pointer value in $a$ is reachable.

Using Definition~\ref{def:atomic}, we make sure that the read of $a$ and the store in $g$ happens
without a reclamation pass in between. Thus all valid pointers before the read is still valid after
the store.  After the store operation in $g$ has completed, $g$ protects $v$. Thus $v$ is valid.
\end{proof}

\begin{lemma}[Ptr is valid]\label{lm:ptr-valid}
  The Ptr points to valid memory.
\end{lemma}
\begin{proof}
The  Ptr $p$ is read from a Guard $g$ and $g$ is immutable throughout the lifetime of $p$ so they
have the same value. $p \neq \bot$, so this follows by Theorem~\ref{thm:guard-valid}.
\end{proof}




\section{Implementation}

The key idea of the implementation is to use an operation known as \emph{forking} to obtain a
snapshot of the entire memory space of the process. Having this we can identify the roots, and run
reachability analysis, knowing that nothing will change while we are looking.

Consolidation starts by sending all running threads a \emph{signal}, causing them to jump to a
\emph{signal handler}. The signal handler registers that the thread has been signaled, such that the
garbage collection pass is detectable. Then the thread writes out the address of a thread local
list of allocated addresses, such that the consolidator can collect all addresses that has been
allocated since the last consolidation. At last, the threads wait for the consolidator to say that
they may return to their execution. \note{why is this required?}

\note{Add implementation details here}

  \code{WAS\_SIGNALED} is a thread local flag that is
  set to \code{true} in the signal handler. Note that this function does not support being called
  recursively.
\begin{figure}[ht]
  \begin{lstlisting}[numbers=left,numberstyle=\color{gray}\ttfamily{}A]
fn atomic(f: F):
  loop:
    WAS_SIGNALED = false
    let ret = f()
    if not WAS_SIGNALED: return ret
\end{lstlisting}
\caption{Pseudocode of $atomic$}
\end{figure}

\begin{theorem}
  If \code{f} does not itself call \code{atomic} then \code{atomic} satisfy
  Definition~\ref{def:atomic}.
\end{theorem}
\begin{proof}
  \code{WAS\_SIGNALED} is set to \code{false} in \code{A3}, so if it is observed to be
  \code{true} in \code{A5} the signal handler must have been executed. Since only the consolidator
  signals any thread, it means that there was a consolidator in this time interval. We are only
  returning from the function if \code{WAS\_SIGNALED = false}, so if we return \code{f} was
  successfully called without overlapping with a pass.
\end{proof}
Note that it is possible that the consolidator was initiated before entering the \code{atomic}
function, but that they only got execution time after \code{A3}.
\begin{lemma}
  If the consolidator is lock-free, then \code{atomic} is lock-free.
\end{lemma}
\begin{proof}
  If we loop, there is a consolidator. Since the consolidate process has a finite number of steps
  and is lock-free, it will either make progress, or some other thread is making progress. In
  either case, the system makes progress.
  \note{this is a terrible proof}
\end{proof}

It is important that the function given to \code{atomic} can be called multiple times without
breaking. The most useful case for \code{atomic} is a \code{load/store} store pair, so this is
usually the case.
